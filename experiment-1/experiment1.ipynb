{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Step: Indexing our Mail DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "#host address with port, \n",
    "#ca_certs: path to the certificate,\n",
    "#basic_auth: username and password\n",
    "es = Elasticsearch(\n",
    "    \"\",\n",
    "    ca_certs=\"\",\n",
    "    basic_auth=(\"\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index name\n",
    "index_name = ''\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"subject\": { \"type\": \"text\"},\n",
    "            \"from\": { \"type\": \"text\" },\n",
    "            \"date\": { \"type\": \"text\" },\n",
    "            \"to\": {  \"type\": \"text\" },\n",
    "            \"cc\": { \"type\": \"text\" },\n",
    "            \"reply-to\": { \"type\": \"text\" },\n",
    "            \"body\": { \"type\": \"text\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create index\n",
    "es.indices.create(index=index_name, body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the dataset folder with all the emails in txt format\n",
    "dataset_path = ''\n",
    "\n",
    "for file in os.listdir(dataset_path):\n",
    "    try:\n",
    "        with open(os.path.join(dataset_path, file), 'r', encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            email = {}\n",
    "            for line in lines:\n",
    "                if line.startswith('Subject:' or 'SUBJECT:'):\n",
    "                    email['subject'] = line[9:]\n",
    "                elif line.startswith('From:' or 'FROM:'):\n",
    "                    email['from'] = line[6:]\n",
    "                elif line.startswith('Date' or 'DATE:'):\n",
    "                    email['date'] = line[6:]\n",
    "                elif line.startswith('To:' or 'TO:'):\n",
    "                    email['to'] = line[4:]\n",
    "                elif line.startswith('Cc:' or 'CC:'):\n",
    "                    email['cc'] = line[4:]\n",
    "                elif line.startswith('Reply-to:' or 'REPLY-TO:'):\n",
    "                    email['reply-to'] = line[10:]\n",
    "                else:\n",
    "                    break\n",
    "            #the rest of the file is the body\n",
    "            email['body'] = ''.join(lines[6:])\n",
    "            \n",
    "            body = {}\n",
    "            if('subject' in email.keys()):\n",
    "                body['subject'] = email['subject']\n",
    "            if('from' in email):\n",
    "                body['from'] = email['from']\n",
    "            if('date' in email):\n",
    "                body['date'] = email['date']\n",
    "            if('to' in email):\n",
    "                body['to'] = email['to']\n",
    "            if('cc' in email):\n",
    "                body['cc'] = email['cc']\n",
    "            if('reply-to' in email):\n",
    "                body['reply-to'] = email['reply-to']\n",
    "            if('body' in email):\n",
    "                body['body'] = email['body']\n",
    "\n",
    "            # Insert document\n",
    "            es.index(index=index_name, body=body)\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the indexing is complete, lets do some search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Hits: 480\n",
      "\n",
      "Document IDs and content of top 10 hits:\n",
      "V-tafYsBXhn-9pfK8ENu\n",
      "MA201_2022 ->Assignment ->Tutorial 7\n",
      "\n",
      "You have submitted an assignment submission for 'Tutorial 7'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "petbfYsBXhn-9pfKG0iJ\n",
      "CS/IT 333_2023 ->Assignment ->1\n",
      "\n",
      "You have submitted an assignment submission for '1'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "M-tafYsBXhn-9pfK70Nc\n",
      "MA201_2022 ->Assignment ->4. Joint Distribution\n",
      "\n",
      "You have submitted an assignment submission for '4. Joint Distribution'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NOtafYsBXhn-9pfK70Nk\n",
      "MA201_2022 ->Assignment ->5. Covariance matrix\n",
      "\n",
      "You have submitted an assignment submission for '5. Covariance matrix'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WetafYsBXhn-9pfK6EKG\n",
      "MA201_2022 ->Assignment ->3. Special Random variables\n",
      "\n",
      "You have submitted an assignment submission for '3. Special Random variables'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dOtafYsBXhn-9pfK4EG4\n",
      "MA201_2022 ->Assignment ->1. Permutations and Combinations\n",
      "\n",
      "You have submitted an assignment submission for '1. Permutations and Combinations'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "F-tafYsBXhn-9pfK5kJy\n",
      "MA201_2022 ->Assignment ->2. PMF,PDF AND CDF\n",
      "\n",
      "You have submitted an assignment submission for '2. PMF,PDF AND CDF'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SOtafYsBXhn-9pfK70P9\n",
      "MA201_2022 ->Assignment ->6. Central limit theorem and distribution of Sampling mean\n",
      "\n",
      "You have submitted an assignment submission for '6. Central limit theorem and distribution of Sampling mean'.\n",
      "\n",
      "You can see the status of your assignment submission.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "retbfYsBXhn-9pfKCkb8\n",
      "Hi SOUMIL,\n",
      "Dr. Manish Khare posted a new announcement in CS202 - System Software.\n",
      "\t\t\t\n",
      "\t\n",
      "New announcement\t\n",
      "Dear Students\n",
      "\n",
      "Assignment of CS202 will be released on 2nd May 2023 at 5:00 PM, and the Last date for submission of the assignment will be on 15th May 2023 5:00 PM.\n",
      "\n",
      "Other details about assignment submission will be circulated with assignment\n",
      "Open\n",
      "Posted May 1 by Dr. Manish Khare\n",
      "Google logo\n",
      "Google LLC 1600 Amphitheatre Parkway, Mountain View, CA 94043 USA\n",
      "If you don't want to receive emails from Classroom, you can unsubscribe.\n",
      "\n",
      "\n",
      "\n",
      "0OtbfYsBXhn-9pfKDEYU\n",
      "Thanks for filling out Assignment Submission Link - CS202\n",
      "Here's what was received.\n",
      "Assignment Submission Link - CS202\n",
      "\n",
      "\n",
      "1. Last Date for Assignment Submission is 15-05-2023 5:00 PM\n",
      "2. You can upload only pdf file.\n",
      "3. Each answer must be upload only in respect question section.\n",
      "Your email (202151161@iiitvadodara.ac.in) was recorded when you submitted this form.\n",
      "Student ID\n",
      "202151161\n",
      "Student Name *\n",
      "Soumil Singh\n",
      "Question 1 *\n",
      "Submitted files\n",
      "PDF\t\tQ1_202151161 - SOUMIL SINGH.pdf\n",
      "Question 2 *\n",
      "Submitted files\n",
      "PDF\t\tQ2_202151161 - SOUMIL SINGH.pdf\n",
      "Question 3 *\n",
      "Submitted files\n",
      "PDF\t\tQ3_202151161 - SOUMIL SINGH.pdf\n",
      "Question 4 *\n",
      "Submitted files\n",
      "PDF\t\tQ4_202151161 - SOUMIL SINGH.pdf\n",
      "Question 5 *\n",
      "Submitted files\n",
      "PDF\t\tQ5_202151161 - SOUMIL SINGH.pdf\n",
      "Question 6 *\n",
      "Submitted files\n",
      "PDF\t\tQ6_202151161 - SOUMIL SINGH.pdf\n",
      "Question 7 *\n",
      "Submitted files\n",
      "PDF\t\tQ7_202151161 - SOUMIL SINGH.pdf\n",
      "Question 8 *\n",
      "Submitted files\n",
      "PDF\t\tQ8_202151161 - SOUMIL SINGH.pdf\n",
      "Question 9 *\n",
      "Submitted files\n",
      "PDF\t\tQ9_202151161 - SOUMIL SINGH.pdf\n",
      "Question 10 *\n",
      "Submitted files\n",
      "PDF\t\tQ10_202151161 - SOUMIL SINGH.pdf\n",
      "Question 11 *\n",
      "Submitted files\n",
      "PDF\t\tQ11_202151161 - SOUMIL SINGH.pdf\n",
      "Question 12 *\n",
      "Submitted files\n",
      "PDF\t\tQ12_202151161 - SOUMIL SINGH.pdf\n",
      "Question 13 *\n",
      "Submitted files\n",
      "PDF\t\tQ13_202151161 - SOUMIL SINGH.pdf\n",
      "Question 14 *\n",
      "Submitted files\n",
      "PDF\t\tQ14_2021511161 - SOUMIL SINGH.pdf\n",
      "Question 15 *\n",
      "Submitted files\n",
      "PDF\t\tQ15_202151161 - SOUMIL SINGH.pdf\n",
      "Create your own Google Form\n",
      "Report Abuse\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#wrtie the query here\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"body\": \"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the query\n",
    "results = es.search(index=index_name, body=query, size=10)  # Adjust the size as needed\n",
    "\n",
    "#print the total number of hits\n",
    "print(\"Total Hits:\", results['hits']['total']['value'])\n",
    "\n",
    "#print the document id of top 10 hits along with the line where the query was found\n",
    "print(\"\\nDocument IDs and content of top 10 hits:\")\n",
    "for hit in results['hits']['hits']:\n",
    "    print(hit['_id'])\n",
    "    print(hit['_source']['body'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets create a bigram and trigram model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = {}\n",
    "trigram_model = {}\n",
    "\n",
    "# Function to generate n-grams\n",
    "def generate_ngrams(tokens, n):\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return list(n_grams)\n",
    "\n",
    "# Tokenize and generate n-grams from email text\n",
    "def process_email(email_text):\n",
    "    tokens = word_tokenize(email_text)\n",
    "    bigrams = generate_ngrams(tokens, 2)\n",
    "    trigrams = generate_ngrams(tokens, 3)\n",
    "    return tokens, bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_name = \"\"  # Change to your desired sender name\n",
    "\n",
    "# Retrieve email text from Elasticsearch and build the models\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            'from': sender_name\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scroll API to retrieve all emails\n",
    "emails = scan(es, index=\"email_dataset\", query=query)\n",
    "\n",
    "for email in emails:\n",
    "    email_text = email[\"_source\"][\"body\"]\n",
    "    tokens, bigrams, trigrams = process_email(email_text)\n",
    "    \n",
    "    # Update the language models with bigrams and trigrams\n",
    "    for bigram in bigrams:\n",
    "        prefix, suffix = bigram\n",
    "        if prefix not in bigram_model:\n",
    "            bigram_model[prefix] = []\n",
    "        bigram_model[prefix].append(suffix)\n",
    "    \n",
    "    for trigram in trigrams:\n",
    "        prefix, suffix = trigram[:2], trigram[2]\n",
    "        if prefix not in trigram_model:\n",
    "            trigram_model[prefix] = []\n",
    "        trigram_model[prefix].append(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text using bigram model\n",
    "def generate_bigram_text(bigram_model, seed_word, max_length=20):\n",
    "    text = [seed_word]\n",
    "    current_word = seed_word\n",
    "    for _ in range(max_length - 1):\n",
    "        if current_word not in bigram_model:\n",
    "            break\n",
    "        next_word = random.choice(bigram_model[current_word])\n",
    "        text.append(next_word)\n",
    "        current_word = next_word\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Function to generate text using trigram model\n",
    "\n",
    "def generate_trigram_text(trigram_model, seed_prefix, max_length=20):\n",
    "    text = list(seed_prefix)\n",
    "    current_prefix = tuple(seed_prefix)  # Convert the prefix to a tuple\n",
    "    for _ in range(max_length - len(seed_prefix)):\n",
    "        if current_prefix not in trigram_model:\n",
    "            break\n",
    "        next_word = random.choice(trigram_model[current_prefix])\n",
    "        text.append(next_word)\n",
    "        current_prefix = tuple(text[-2:])  # Update current_prefix as a tuple\n",
    "    return \" \".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSender Name:\", sender_name)  # Print the sender name\n",
    "\n",
    "# Generate random text for a seed word\n",
    "seed_word = \"\"  # Change to your desired seed word\n",
    "max_length = 10  # Adjust the maximum length of the generated text\n",
    "\n",
    "# Generate bigram text for the seed word\n",
    "generated_bigram_text = generate_bigram_text(bigram_model, seed_word, max_length)\n",
    "print(\"\\nSeed Word:\", seed_word)\n",
    "print(\"Text Generated by Bigram Model:\")\n",
    "print(generated_bigram_text)\n",
    "\n",
    "# Generate random text for a seed prefix\n",
    "seed_prefix = (\"\", \"\")  # Change to your desired seed prefix\n",
    "max_length = 20  # Adjust the maximum length of the generated text\n",
    "\n",
    "# Generate trigram text for the seed prefix\n",
    "generated_trigram_text = generate_trigram_text(trigram_model, seed_prefix, max_length)\n",
    "print(\"\\nSeed Prefix:\", seed_prefix)\n",
    "print(\"Text Generated by Trigram Model:\")\n",
    "print(generated_trigram_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
