{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES CLASSIFICATION\n",
      "Confusion Matrix : \n",
      "[[245   0   0   1   0   1   0   0   1   0   2   1   1   2   2  41   2  11\n",
      "    5   4]\n",
      " [  1 287   0  12   4  31   1   0   0   1   0  26   5   2   8   2   2   1\n",
      "    6   0]\n",
      " [  2  55   1 134  13 112   2   0   1   3   1  31   4   4   8   5   2   1\n",
      "   14   1]\n",
      " [  0  11   1 300  15  11   3   5   0   0   1  11  23   0   5   0   1   2\n",
      "    3   0]\n",
      " [  0  12   1  22 289   5   3   5   1   1   0  14  10   3   3   1   4   2\n",
      "    9   0]\n",
      " [  1  25   2  11   1 332   0   0   0   0   0  13   0   2   4   1   2   1\n",
      "    0   0]\n",
      " [  0   6   0  35  17   3 253  16   4   1   4   6  16   7   6   2   5   4\n",
      "    5   0]\n",
      " [  0   1   0   2   0   0   4 360   3   2   2   3   0   0   4   0   4   2\n",
      "    9   0]\n",
      " [  0   0   0   1   0   0   2  13 365   0   0   4   0   0   0   1   3   4\n",
      "    5   0]\n",
      " [  1   1   0   0   1   1   0   6   0 345  16   0   0   0   5   6   2   2\n",
      "   11   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2 385   1   0   1   1   3   1   2\n",
      "    3   0]\n",
      " [  0   3   0   0   0   2   1   2   0   0   0 377   2   1   1   0   2   1\n",
      "    4   0]\n",
      " [  0  14   0  17   5   5   0   5   1   0   1  58 261  11   6   2   1   3\n",
      "    3   0]\n",
      " [  7   6   0   2   0   0   1   1   0   2   1   4   5 325   3  16   1   7\n",
      "   15   0]\n",
      " [  1   4   0   0   0   4   0   1   0   0   0   1   2   4 351   5   2   3\n",
      "   16   0]\n",
      " [  3   2   0   0   0   1   0   0   0   0   1   0   0   2   2 382   0   1\n",
      "    0   4]\n",
      " [  0   0   0   1   0   0   1   0   3   0   0   6   0   1   0   2 330   6\n",
      "   13   1]\n",
      " [  1   1   0   0   0   2   0   0   0   1   0   3   0   2   0   3   2 354\n",
      "    7   0]\n",
      " [  1   0   0   0   0   0   0   1   0   0   0   4   0   2  10   5  87   5\n",
      "  195   0]\n",
      " [ 47   2   0   0   0   0   0   0   0   0   1   2   0   3   3  70  22   5\n",
      "   12  84]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       319\n",
      "           1       0.67      0.74      0.70       389\n",
      "           2       0.20      0.00      0.01       394\n",
      "           3       0.56      0.77      0.65       392\n",
      "           4       0.84      0.75      0.79       385\n",
      "           5       0.65      0.84      0.73       395\n",
      "           6       0.93      0.65      0.77       390\n",
      "           7       0.87      0.91      0.89       396\n",
      "           8       0.96      0.92      0.94       398\n",
      "           9       0.96      0.87      0.91       397\n",
      "          10       0.93      0.96      0.95       399\n",
      "          11       0.67      0.95      0.78       396\n",
      "          12       0.79      0.66      0.72       393\n",
      "          13       0.87      0.82      0.85       396\n",
      "          14       0.83      0.89      0.86       394\n",
      "          15       0.70      0.96      0.81       398\n",
      "          16       0.69      0.91      0.79       364\n",
      "          17       0.85      0.94      0.89       376\n",
      "          18       0.58      0.63      0.60       310\n",
      "          19       0.89      0.33      0.49       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.76      0.76      0.75      7532\n",
      "weighted avg       0.76      0.77      0.75      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Extract features from text using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, newsgroups_train.target)\n",
    "\n",
    "#Test the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"NAIVE BAYES CLASSIFICATION\")\n",
    "print(\"Confusion Matrix : \")\n",
    "\n",
    "print(confusion_matrix(newsgroups_test.target, y_pred))\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(newsgroups_test.target, y_pred))\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# f1 = f1_score(newsgroups_test.target, y_pred, average='weighted')\n",
    "# print(\"F1 Score for Naive Bayes:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCCHIO CLASSIFICATION\n",
      "Confusion Matrix : \n",
      "[[ 77   2   0   0   0   0   0   1   2   0   0   0   9   2   2  14   4   4\n",
      "   15  19]\n",
      " [  3 119  17  11   2   6   1   0   0   0   0   0  31   1   5   0   0   0\n",
      "    3   3]\n",
      " [  3  12 114  13   6   6   0   0   1   1   0   0  34   0   0   1   1   0\n",
      "    2   1]\n",
      " [  1  12  20 102  13   4   4   1   0   0   0   0  23   2   0   0   0   0\n",
      "    0   1]\n",
      " [  2   7   1  22 129   0   3   2   0   0   0   0  31   1   2   0   1   0\n",
      "    3   1]\n",
      " [  1  24  16   2   2 151   0   0   2   0   0   0  13   1   1   0   0   0\n",
      "    2   0]\n",
      " [  0   2   3  27   6   1 110   8   0   1   3   1  25   0   2   1   0   0\n",
      "    3   0]\n",
      " [  4   0   0   0   0   1   2 132   6   2   0   0  34   4   1   0   3   0\n",
      "    6   1]\n",
      " [  2   2   0   0   0   0   7  11 109   2   2   0  20   0   1   1   3   0\n",
      "    7   1]\n",
      " [  4   0   0   0   0   1   2   0   3 162  10   0  20   1   0   0   0   2\n",
      "    3   3]\n",
      " [  2   1   0   0   0   0   2   2   3  12 153   0  13   2   1   0   0   0\n",
      "    4   3]\n",
      " [  3   5   2   0   3   0   0   0   1   0   0 116  31   0   2   0   7   1\n",
      "   28   2]\n",
      " [  3   4   3   9   4   0   8   7   0   2   0   1 153   4   2   0   1   0\n",
      "    0   1]\n",
      " [  7   2   0   0   0   0   2   0   3   1   0   0  31 137   1   0   0   0\n",
      "    6   4]\n",
      " [  3   2   1   0   1   0   2   0   2   3   0   0  27   2 137   0   0   0\n",
      "    7   2]\n",
      " [ 18   1   0   0   0   0   0   0   1   3   0   0  15   1   0 127   0   5\n",
      "    6  25]\n",
      " [  2   0   0   0   0   0   0   0   2   2   0   1  19   0   2   2 128   0\n",
      "   25   5]\n",
      " [ 12   0   0   0   0   0   0   1   2   0   0   2  20   1   0   2   1 120\n",
      "   18   3]\n",
      " [  2   0   0   0   0   0   1   2   0   1   0   0  17   3   4   1  16   0\n",
      "  106   6]\n",
      " [ 32   0   0   0   0   0   0   1   1   2   0   0  12   1   2  26   9   1\n",
      "    8  41]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.51      0.46       151\n",
      "           1       0.61      0.59      0.60       202\n",
      "           2       0.64      0.58      0.61       195\n",
      "           3       0.55      0.56      0.55       183\n",
      "           4       0.78      0.63      0.70       205\n",
      "           5       0.89      0.70      0.78       215\n",
      "           6       0.76      0.57      0.65       193\n",
      "           7       0.79      0.67      0.73       196\n",
      "           8       0.79      0.65      0.71       168\n",
      "           9       0.84      0.77      0.80       211\n",
      "          10       0.91      0.77      0.84       198\n",
      "          11       0.96      0.58      0.72       201\n",
      "          12       0.26      0.76      0.39       202\n",
      "          13       0.84      0.71      0.77       194\n",
      "          14       0.83      0.72      0.77       189\n",
      "          15       0.73      0.63      0.67       202\n",
      "          16       0.74      0.68      0.71       188\n",
      "          17       0.90      0.66      0.76       182\n",
      "          18       0.42      0.67      0.52       159\n",
      "          19       0.34      0.30      0.32       136\n",
      "\n",
      "    accuracy                           0.64      3770\n",
      "   macro avg       0.70      0.64      0.65      3770\n",
      "weighted avg       0.71      0.64      0.66      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the 20 newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Preprocess the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "X = vectorizer.fit_transform(newsgroups.data)\n",
    "y = newsgroups.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Rocchio classifier on the training set\n",
    "clf = NearestCentroid()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the classifier on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "# print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "# print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "# print('Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "# print('F1-score:', f1_score(y_test, y_pred, average='macro'))\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"ROCCHIO CLASSIFICATION\")\n",
    "print(\"Confusion Matrix : \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report : \")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#print('F1-score for Rocchio classifier:', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFICATION\n",
      "Confusion Matrix : \n",
      "[[ 13   0 136   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   2]\n",
      " [  6   8 188   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   1 192   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 170   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 11   0 186   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 18   0 192   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 181   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8   0 185   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 154   0   0   0   0   0   7   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0 198   0   0   0   0   0   0  11   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  6   0 177   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 189   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 186   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0 174   0   0   0   0   0   0   0   0   0   0  19   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 177   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0\n",
      "    0   0]\n",
      " [  5   0 195   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
      "    0   0]\n",
      " [  4   0 181   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "    0   0]\n",
      " [ 12   0 157   0   0   0   0   1   0   0   0   0   0   0   0   0   0  12\n",
      "    0   0]\n",
      " [  3   0 146   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    9   0]\n",
      " [  6   0 127   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   2]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.09      0.09       151\n",
      "           1       0.89      0.04      0.08       202\n",
      "           2       0.05      0.98      0.10       195\n",
      "           3       0.86      0.03      0.06       183\n",
      "           4       1.00      0.04      0.08       205\n",
      "           5       1.00      0.02      0.05       215\n",
      "           6       1.00      0.03      0.05       193\n",
      "           7       0.60      0.02      0.03       196\n",
      "           8       1.00      0.04      0.08       168\n",
      "           9       1.00      0.05      0.10       211\n",
      "          10       0.94      0.08      0.14       198\n",
      "          11       1.00      0.02      0.05       201\n",
      "          12       1.00      0.04      0.09       202\n",
      "          13       1.00      0.10      0.18       194\n",
      "          14       1.00      0.03      0.05       189\n",
      "          15       1.00      0.01      0.02       202\n",
      "          16       0.75      0.02      0.03       188\n",
      "          17       1.00      0.07      0.12       182\n",
      "          18       1.00      0.06      0.11       159\n",
      "          19       0.50      0.01      0.03       136\n",
      "\n",
      "    accuracy                           0.09      3770\n",
      "   macro avg       0.83      0.09      0.08      3770\n",
      "weighted avg       0.85      0.09      0.08      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Preprocess the data\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "X_counts = count_vect.fit_transform(newsgroups.data)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, newsgroups.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the k-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = knn.predict(X_test)\n",
    "# print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "# print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "# print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "# print('F1 score:', f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"KNN CLASSIFICATION\")\n",
    "print(\"Confusion Matrix : \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report : \")\n",
    "\n",
    "print( classification_report(y_test, y_pred))\n",
    "#print('F1 score using KNN classification:', f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7532, 3770]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sudha\\OneDrive\\Documents\\IR\\classification.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sudha/OneDrive/Documents/IR/classification.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mF1 Score for Naive Bayes:\u001b[39m\u001b[39m\"\u001b[39m, f1_score(newsgroups_test\u001b[39m.\u001b[39;49mtarget, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mweighted\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudha/OneDrive/Documents/IR/classification.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mF1-score for Rocchio classifier:\u001b[39m\u001b[39m'\u001b[39m, f1_score(y_test, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sudha/OneDrive/Documents/IR/classification.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mF1 score using KNN classification:\u001b[39m\u001b[39m'\u001b[39m, f1_score(y_test, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1238\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1071\u001b[0m     {\n\u001b[0;32m   1072\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1096\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1097\u001b[0m ):\n\u001b[0;32m   1098\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \n\u001b[0;32m   1100\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1239\u001b[0m         y_true,\n\u001b[0;32m   1240\u001b[0m         y_pred,\n\u001b[0;32m   1241\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1242\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1243\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1244\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1245\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1246\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1247\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1411\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1251\u001b[0m     {\n\u001b[0;32m   1252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1279\u001b[0m ):\n\u001b[0;32m   1280\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1281\u001b[0m \n\u001b[0;32m   1282\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[39m    0.38...\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1412\u001b[0m         y_true,\n\u001b[0;32m   1413\u001b[0m         y_pred,\n\u001b[0;32m   1414\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1415\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1416\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1417\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1418\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1419\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1420\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1421\u001b[0m     )\n\u001b[0;32m   1422\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m \n\u001b[0;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1500\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7532, 3770]"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"F1 Score for Naive Bayes:\", f1_score(newsgroups_test.target, y_pred, average='weighted'))\n",
    "print('F1-score for Rocchio classifier:', f1_score(y_test, y_pred, average='macro'))\n",
    "print('F1 score using KNN classification:', f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
