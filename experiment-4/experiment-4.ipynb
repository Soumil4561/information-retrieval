{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES CLASSIFICATION\n",
      "Confusion Matrix : \n",
      "[[245   0   0   1   0   1   0   0   1   0   2   1   1   2   2  41   2  11\n",
      "    5   4]\n",
      " [  1 287   0  12   4  31   1   0   0   1   0  26   5   2   8   2   2   1\n",
      "    6   0]\n",
      " [  2  55   1 134  13 112   2   0   1   3   1  31   4   4   8   5   2   1\n",
      "   14   1]\n",
      " [  0  11   1 300  15  11   3   5   0   0   1  11  23   0   5   0   1   2\n",
      "    3   0]\n",
      " [  0  12   1  22 289   5   3   5   1   1   0  14  10   3   3   1   4   2\n",
      "    9   0]\n",
      " [  1  25   2  11   1 332   0   0   0   0   0  13   0   2   4   1   2   1\n",
      "    0   0]\n",
      " [  0   6   0  35  17   3 253  16   4   1   4   6  16   7   6   2   5   4\n",
      "    5   0]\n",
      " [  0   1   0   2   0   0   4 360   3   2   2   3   0   0   4   0   4   2\n",
      "    9   0]\n",
      " [  0   0   0   1   0   0   2  13 365   0   0   4   0   0   0   1   3   4\n",
      "    5   0]\n",
      " [  1   1   0   0   1   1   0   6   0 345  16   0   0   0   5   6   2   2\n",
      "   11   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2 385   1   0   1   1   3   1   2\n",
      "    3   0]\n",
      " [  0   3   0   0   0   2   1   2   0   0   0 377   2   1   1   0   2   1\n",
      "    4   0]\n",
      " [  0  14   0  17   5   5   0   5   1   0   1  58 261  11   6   2   1   3\n",
      "    3   0]\n",
      " [  7   6   0   2   0   0   1   1   0   2   1   4   5 325   3  16   1   7\n",
      "   15   0]\n",
      " [  1   4   0   0   0   4   0   1   0   0   0   1   2   4 351   5   2   3\n",
      "   16   0]\n",
      " [  3   2   0   0   0   1   0   0   0   0   1   0   0   2   2 382   0   1\n",
      "    0   4]\n",
      " [  0   0   0   1   0   0   1   0   3   0   0   6   0   1   0   2 330   6\n",
      "   13   1]\n",
      " [  1   1   0   0   0   2   0   0   0   1   0   3   0   2   0   3   2 354\n",
      "    7   0]\n",
      " [  1   0   0   0   0   0   0   1   0   0   0   4   0   2  10   5  87   5\n",
      "  195   0]\n",
      " [ 47   2   0   0   0   0   0   0   0   0   1   2   0   3   3  70  22   5\n",
      "   12  84]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       319\n",
      "           1       0.67      0.74      0.70       389\n",
      "           2       0.20      0.00      0.01       394\n",
      "           3       0.56      0.77      0.65       392\n",
      "           4       0.84      0.75      0.79       385\n",
      "           5       0.65      0.84      0.73       395\n",
      "           6       0.93      0.65      0.77       390\n",
      "           7       0.87      0.91      0.89       396\n",
      "           8       0.96      0.92      0.94       398\n",
      "           9       0.96      0.87      0.91       397\n",
      "          10       0.93      0.96      0.95       399\n",
      "          11       0.67      0.95      0.78       396\n",
      "          12       0.79      0.66      0.72       393\n",
      "          13       0.87      0.82      0.85       396\n",
      "          14       0.83      0.89      0.86       394\n",
      "          15       0.70      0.96      0.81       398\n",
      "          16       0.69      0.91      0.79       364\n",
      "          17       0.85      0.94      0.89       376\n",
      "          18       0.58      0.63      0.60       310\n",
      "          19       0.89      0.33      0.49       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.76      0.76      0.75      7532\n",
      "weighted avg       0.76      0.77      0.75      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Extract features from text using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, newsgroups_train.target)\n",
    "\n",
    "#Test the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"NAIVE BAYES CLASSIFICATION\")\n",
    "print(\"Confusion Matrix : \")\n",
    "\n",
    "print(confusion_matrix(newsgroups_test.target, y_pred))\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(newsgroups_test.target, y_pred))\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# f1 = f1_score(newsgroups_test.target, y_pred, average='weighted')\n",
    "# print(\"F1 Score for Naive Bayes:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCCHIO CLASSIFICATION\n",
      "Confusion Matrix : \n",
      "[[ 77   2   0   0   0   0   0   1   2   0   0   0   9   2   2  14   4   4\n",
      "   15  19]\n",
      " [  3 119  17  11   2   6   1   0   0   0   0   0  31   1   5   0   0   0\n",
      "    3   3]\n",
      " [  3  12 114  13   6   6   0   0   1   1   0   0  34   0   0   1   1   0\n",
      "    2   1]\n",
      " [  1  12  20 102  13   4   4   1   0   0   0   0  23   2   0   0   0   0\n",
      "    0   1]\n",
      " [  2   7   1  22 129   0   3   2   0   0   0   0  31   1   2   0   1   0\n",
      "    3   1]\n",
      " [  1  24  16   2   2 151   0   0   2   0   0   0  13   1   1   0   0   0\n",
      "    2   0]\n",
      " [  0   2   3  27   6   1 110   8   0   1   3   1  25   0   2   1   0   0\n",
      "    3   0]\n",
      " [  4   0   0   0   0   1   2 132   6   2   0   0  34   4   1   0   3   0\n",
      "    6   1]\n",
      " [  2   2   0   0   0   0   7  11 109   2   2   0  20   0   1   1   3   0\n",
      "    7   1]\n",
      " [  4   0   0   0   0   1   2   0   3 162  10   0  20   1   0   0   0   2\n",
      "    3   3]\n",
      " [  2   1   0   0   0   0   2   2   3  12 153   0  13   2   1   0   0   0\n",
      "    4   3]\n",
      " [  3   5   2   0   3   0   0   0   1   0   0 116  31   0   2   0   7   1\n",
      "   28   2]\n",
      " [  3   4   3   9   4   0   8   7   0   2   0   1 153   4   2   0   1   0\n",
      "    0   1]\n",
      " [  7   2   0   0   0   0   2   0   3   1   0   0  31 137   1   0   0   0\n",
      "    6   4]\n",
      " [  3   2   1   0   1   0   2   0   2   3   0   0  27   2 137   0   0   0\n",
      "    7   2]\n",
      " [ 18   1   0   0   0   0   0   0   1   3   0   0  15   1   0 127   0   5\n",
      "    6  25]\n",
      " [  2   0   0   0   0   0   0   0   2   2   0   1  19   0   2   2 128   0\n",
      "   25   5]\n",
      " [ 12   0   0   0   0   0   0   1   2   0   0   2  20   1   0   2   1 120\n",
      "   18   3]\n",
      " [  2   0   0   0   0   0   1   2   0   1   0   0  17   3   4   1  16   0\n",
      "  106   6]\n",
      " [ 32   0   0   0   0   0   0   1   1   2   0   0  12   1   2  26   9   1\n",
      "    8  41]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.51      0.46       151\n",
      "           1       0.61      0.59      0.60       202\n",
      "           2       0.64      0.58      0.61       195\n",
      "           3       0.55      0.56      0.55       183\n",
      "           4       0.78      0.63      0.70       205\n",
      "           5       0.89      0.70      0.78       215\n",
      "           6       0.76      0.57      0.65       193\n",
      "           7       0.79      0.67      0.73       196\n",
      "           8       0.79      0.65      0.71       168\n",
      "           9       0.84      0.77      0.80       211\n",
      "          10       0.91      0.77      0.84       198\n",
      "          11       0.96      0.58      0.72       201\n",
      "          12       0.26      0.76      0.39       202\n",
      "          13       0.84      0.71      0.77       194\n",
      "          14       0.83      0.72      0.77       189\n",
      "          15       0.73      0.63      0.67       202\n",
      "          16       0.74      0.68      0.71       188\n",
      "          17       0.90      0.66      0.76       182\n",
      "          18       0.42      0.67      0.52       159\n",
      "          19       0.34      0.30      0.32       136\n",
      "\n",
      "    accuracy                           0.64      3770\n",
      "   macro avg       0.70      0.64      0.65      3770\n",
      "weighted avg       0.71      0.64      0.66      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the 20 newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Preprocess the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "X = vectorizer.fit_transform(newsgroups.data)\n",
    "y = newsgroups.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Rocchio classifier on the training set\n",
    "clf = NearestCentroid()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the classifier on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "# print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "# print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "# print('Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "# print('F1-score:', f1_score(y_test, y_pred, average='macro'))\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"ROCCHIO CLASSIFICATION\")\n",
    "print(\"Confusion Matrix : \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report : \")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "#print('F1-score for Rocchio classifier:', f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFICATION\n",
      "Confusion Matrix : \n",
      "[[ 13   0 136   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   2]\n",
      " [  6   8 188   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   1 192   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 170   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 11   0 186   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 18   0 192   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 181   0   0   0   5   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8   0 185   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 154   0   0   0   0   0   7   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0 198   0   0   0   0   0   0  11   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  6   0 177   0   0   0   0   0   0   0  15   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 189   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 186   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0 174   0   0   0   0   0   0   0   0   0   0  19   0   0   0   0\n",
      "    0   0]\n",
      " [  7   0 177   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0\n",
      "    0   0]\n",
      " [  5   0 195   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0\n",
      "    0   0]\n",
      " [  4   0 181   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "    0   0]\n",
      " [ 12   0 157   0   0   0   0   1   0   0   0   0   0   0   0   0   0  12\n",
      "    0   0]\n",
      " [  3   0 146   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    9   0]\n",
      " [  6   0 127   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   2]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.09      0.09       151\n",
      "           1       0.89      0.04      0.08       202\n",
      "           2       0.05      0.98      0.10       195\n",
      "           3       0.86      0.03      0.06       183\n",
      "           4       1.00      0.04      0.08       205\n",
      "           5       1.00      0.02      0.05       215\n",
      "           6       1.00      0.03      0.05       193\n",
      "           7       0.60      0.02      0.03       196\n",
      "           8       1.00      0.04      0.08       168\n",
      "           9       1.00      0.05      0.10       211\n",
      "          10       0.94      0.08      0.14       198\n",
      "          11       1.00      0.02      0.05       201\n",
      "          12       1.00      0.04      0.09       202\n",
      "          13       1.00      0.10      0.18       194\n",
      "          14       1.00      0.03      0.05       189\n",
      "          15       1.00      0.01      0.02       202\n",
      "          16       0.75      0.02      0.03       188\n",
      "          17       1.00      0.07      0.12       182\n",
      "          18       1.00      0.06      0.11       159\n",
      "          19       0.50      0.01      0.03       136\n",
      "\n",
      "    accuracy                           0.09      3770\n",
      "   macro avg       0.83      0.09      0.08      3770\n",
      "weighted avg       0.85      0.09      0.08      3770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Preprocess the data\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "X_counts = count_vect.fit_transform(newsgroups.data)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, newsgroups.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the k-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = knn.predict(X_test)\n",
    "# print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "# print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "# print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "# print('F1 score:', f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"KNN CLASSIFICATION\")\n",
    "print(\"Confusion Matrix : \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report : \")\n",
    "\n",
    "print( classification_report(y_test, y_pred))\n",
    "#print('F1 score using KNN classification:', f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"F1 Score for Naive Bayes:\", f1_score(newsgroups_test.target, y_pred, average='weighted'))\n",
    "print('F1-score for Rocchio classifier:', f1_score(y_test, y_pred, average='macro'))\n",
    "print('F1 score using KNN classification:', f1_score(y_test, y_pred, average='weighted'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
